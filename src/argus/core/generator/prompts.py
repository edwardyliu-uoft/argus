"""Prompts for test generation phase."""

import json
from typing import List, Dict
from pathlib import Path


def test_generation_prompt(
    contract_name: str,
    contract_code: str,
    contract_endpoints: List[Dict],
    contract_findings: List[Dict],
    project_semantic_findings: List[Dict],
    output_path: Path,
    project_root: Path,
) -> str:
    """Build comprehensive prompt for test generation.

    Includes:
    - Full project-level semantic analysis (always included for context)
    - Contract code and endpoints
    - Contract-specific findings
    - Instructions for writing tests with filesystem tools
    - Iterative compile-test-fix workflow

    Args:
        contract_name: Name of the contract (without .sol)
        contract_code: Contract source code
        contract_endpoints: Extracted function endpoints
        contract_findings: Contract-specific findings
        project_semantic_findings: Project-level semantic findings
        output_path: Path where test file should be written
        project_root: Project root directory

    Returns:
        Complete prompt string
    """
    # Build context sections
    sections = []

    # Section 1: Project-level semantic analysis (ALWAYS included)
    sections.append("## Project-Level Semantic Analysis\n")
    sections.append(
        "**Important**: The following findings apply to the entire project and provide important context.\n"
    )

    if project_semantic_findings:
        sections.append("**Project Findings**:")
        sections.append(json.dumps(project_semantic_findings, indent=2))
    else:
        sections.append("No project-level semantic findings.")

    # Section 2: Contract details
    sections.append(f"\n## Contract: {contract_name}\n")
    sections.append("**Source Code**:")
    sections.append(f"```solidity\n{contract_code}\n```\n")

    sections.append("**Endpoints**:")
    sections.append(json.dumps(contract_endpoints, indent=2))

    # Section 3: Contract-specific findings
    sections.append("\n## Contract-Specific Vulnerabilities\n")
    if contract_findings:
        sections.append(json.dumps(contract_findings, indent=2))
    else:
        sections.append("No contract-specific findings.")

    # Section 4: Instructions
    sections.append("\n## Your Task\n")
    sections.append(
        f"""
Generate comprehensive Hardhat test cases for the {contract_name} contract that:

1. **Demonstrate all vulnerabilities** found in the analysis (both contract-specific and relevant project-level issues)
2. **Compile and run successfully** without unexpected errors
3. **Follow Hardhat/Ethers.js syntax** exactly
4. **CRITICAL: Only call functions that actually exist in the contract source code above** - do NOT invent or hallucinate methods

**Project Context**:
- Project root: `{project_root}`
- Test file location: `{output_path}`
- Helper contracts location: `{project_root}/contracts/test-helpers/`
- Use project root as cwd when running commands

**IMPORTANT**: Carefully review the contract source code provided above. Only use functions, state variables, and events that are explicitly defined in the contract. Do not assume functions exist - verify them in the source code first.

**Test File Requirements**:
- File path: `{output_path}`
- Use describe/it blocks
- Include setup in beforeEach
- Each test should demonstrate a specific vulnerability
- Include comments explaining what each test demonstrates
- Clearly indicate if a test is EXPECTED to pass or EXPECTED to fail

**Test Structure Template**:
```javascript
/**
 * Argus Auto-Generated Security Test
 * Generated for: {contract_name}
 * DO NOT EDIT - This file is automatically generated and may be overwritten
 */

const {{ expect }} = require("chai");
const {{ ethers }} = require("hardhat");

describe("{contract_name} Security Tests", function() {{
  let contract;
  let owner, attacker, user;

  beforeEach(async function() {{
    [owner, attacker, user] = await ethers.getSigners();
    const Contract = await ethers.getContractFactory("{contract_name}");
    contract = await Contract.deploy();
  }});

  it("Should demonstrate [vulnerability name]", async function() {{
    // Setup: Prepare the exploit scenario

    // Exploit: Execute the attack

    // Assert: Verify the exploit worked (test should PASS if vulnerability exists)
  }});
}});
```

**Iterative Development Workflow**:

You MUST follow this workflow to ensure tests compile and run correctly:

1. **Write Test File**: Use `write_file` to create the test at: `{output_path}`
   - NOTE: This file uses the "Argus." prefix to distinguish auto-generated tests from user-written tests

2. **Create Helper Contracts** (if needed):
   - If your test needs helper contracts (e.g., ReentrancyAttacker, MockToken):
   - Write them to: `{project_root}/contracts/test-helpers/<ContractName>.sol`
   - Example: `{project_root}/contracts/test-helpers/ReentrancyAttacker.sol`
   - Use proper Solidity syntax with SPDX license and pragma statements

3. **Compile Contracts**:
   - Run: `hardhat` with command="compile", cwd="{project_root}"
   - If compilation FAILS:
     - Read the error output carefully
     - Common issues: syntax errors, missing imports, wrong Solidity version, missing contracts
     - Fix the test file or helper contracts using `write_file`
     - Run compile again
   - Repeat until compilation succeeds

4. **Run Tests**:
   - Run: `hardhat` with command="test", args=["{output_path}"], cwd="{project_root}"
   - Analyze the output carefully:
     - ✓ PASSING tests = Good (vulnerability confirmed or expected behavior)
     - ✗ FAILING tests = Check if expected or unexpected
       - If you INTENDED the test to fail (e.g., testing an invariant), that's OK
       - If UNEXPECTED failure: fix the test code and rerun
     - **Runtime errors/exceptions** = You called a function that doesn't exist or used wrong syntax
       - Example: "contract.getContractBalance is not a function" means you invented a method
       - FIX: Review the contract source code and use only methods that actually exist
       - Example: "invalid opcode" often means you're calling a non-existent function
   - Repeat until tests run without unexpected failures

5. **Clean on Error** (optional):
   - If you encounter caching issues, run: `hardhat` with command="clean", cwd="{project_root}"
   - Then recompile

**Available Tools**:
- `write_file`: Write test files and helper contracts
- `read_file`: Read existing files if needed for debugging
- `hardhat`: Compile and test using hardhat command line interface (whitelisted commands: compile, test, clean)

**Success Criteria**:
- ✅ All contracts and tests compile without errors
- ✅ Tests execute without runtime exceptions
- ✅ Test results match your expectations (passing or failing as intended)

**IMPORTANT**:
- Use the tools iteratively - write, compile, fix errors, test, fix issues
- Make sure to write valid JavaScript/Hardhat test code
- Focus on the most critical vulnerabilities first
- Each test should be clear and well-commented
- Clearly document which tests are expected to pass vs fail
"""
    )

    return "\n".join(sections)
